{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb_ajqWXuguV"
   },
   "source": [
    "## Загрузим нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MTgpe_1quUDs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import imblearn\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "def fit_plot_confusion(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train )\n",
    "\n",
    "    mean, std = clf.cv_results_['mean_test_score'][clf.best_index_], \\\n",
    "                clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "\n",
    "    logging.info(clf.best_params_)\n",
    "\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test , normalize='true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return clf.best_estimator_, {\"mean\": mean, \"std\": std}\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "def calculate_age(born):\n",
    "    f = \"%Y-%m-%d 00:00:00.000\"\n",
    "    born = datetime.strptime(born, f)\n",
    "    today = date.today()\n",
    "    return today.year - born.year - ((today.month, 5) < (born.month, born.day))\n",
    "\n",
    "def calculate_monBr(born):\n",
    "    f = \"%Y-%m-%d 00:00:00.000\"\n",
    "    born = datetime.strptime(born, f)\n",
    "    return born.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_dataset_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/train_dataset_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df_q \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_dataset_test.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplaceInRow\u001b[39m(df_m, ColName, search, replace):\n\u001b[0;32m      7\u001b[0m     df_m[ColName] \u001b[38;5;241m=\u001b[39m df_m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[ColName] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(row[ColName])\u001b[38;5;241m.\u001b[39mfind(search) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m  replace, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_dataset_test.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_dataset_train.csv\")\n",
    "\n",
    "\n",
    "\n",
    "def replaceInRow(df_m, ColName, search, replace):\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(search) == -1 else  replace, axis=1)\n",
    "\n",
    "def replaceInRowSimple(df_m, ColName, search, replace):\n",
    "    df_m[ColName] = df_m.apply(lambda row: str(row[ColName]).replace(search, replace) , axis=1)\n",
    "    \n",
    "def topoFixCountry(df_m, ColName):    \n",
    "    replaceInRow(df_m, ColName, 'РОССИЯ', 'Россия')\n",
    "    replaceInRow(df_m, ColName, 'Казах', 'Казахстан')\n",
    "    replaceInRow(df_m, ColName, 'аджи', 'Таджикистан')\n",
    "    replaceInRow(df_m, ColName, 'ырг', 'Киргизия')\n",
    "    replaceInRow(df_m, ColName, 'Росссия', 'Россия')\n",
    "    \n",
    "def topoFix(df_m, ColName):\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"Китай\") == -1 else  \"Китай\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"КНР\") == -1 else  \"Китай\", axis=1)\n",
    "\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"арнаул\") == -1 else  \"Барнаул\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"убцовск\") == -1 else  \"Рубцовск\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"овоалтайск\") == -1 else  \"Барнаул\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"Бийск\") == -1 else  \"Бийск\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"Славгород\") == -1 else  \"Славгород\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"Заринск\") == -1 else  \"Заринск\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"Камень\") == -1 else  \"Камень-на-Оби\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"орно-\") == -1 else  \"Горно-Алтайск\", axis=1)\n",
    "    \n",
    "\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"с.\") == -1 else  \"Село\", axis=1)\n",
    "\n",
    "    df_m[ColName] = df_m.apply(lambda row: \"АлтСело\" if row[ColName] == 'Село'and row['Регион_ПП'] == 'Алтайский край' else row[ColName],  axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"г.\") == -1 else  \"Город\", axis=1)\n",
    "\n",
    "    df_m[ColName] = df_m.apply(lambda row: \"АлтГород\" if row[ColName] == 'Город'and row['Регион_ПП'] == 'Алтайский край' else row[ColName],  axis=1)\n",
    "\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"р-н\") == -1 else  \"СелоРайон\", axis=1)\n",
    "    df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"район\") == -1 else  \"СелоРайон\", axis=1)\n",
    "\n",
    "    df_m[ColName] = df_m.apply(lambda row: \"АлтСелоРайон\" if row[ColName] == 'СелоРайон'and row['Регион_ПП'] == 'Алтайский край' else row[ColName],  axis=1)\n",
    "    \n",
    "    \n",
    "###\n",
    "    if True:\n",
    "\n",
    "        \n",
    "        \n",
    "        df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\" с\") == -1 else  \"Село\", axis=1)\n",
    "\n",
    "        df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\"с \") == -1 else  \"Село\", axis=1)\n",
    "        \n",
    "     \n",
    "\n",
    "        df_m[ColName] = df_m.apply(lambda row: row[ColName] if str(row[ColName]).find(\" г\") == -1 else  \"Город\", axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def fixValues(df_m):\n",
    "    \n",
    "    \n",
    "    \n",
    "    #agu_name = 'ФГБОУ ВО Алтайский государственный университет'\n",
    "    #polith_name = 'ФГБОУ ВО Алтайский государственный технический университет им. И.И. Ползунова'\n",
    "    agu_name = 'АГУ'\n",
    "    polith_name = 'АГТУ'\n",
    "    \n",
    "    \n",
    "    df_m['Уч_Заведение'].fillna('', inplace=True)\n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'ФГБОУ ВПО Алтайский государственный университет', agu_name)\n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'Ползу', polith_name)\n",
    "    replaceInRowSimple(df_m, 'Уч_Заведение', 'Горно-Алтайский', 'Г-А')\n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'Алтайский государственный университет', agu_name)\n",
    "    \n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'СОШ', 'СОШ')\n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'Гимназия', 'Гимназия')\n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'ицей', 'Лицей')\n",
    "    \n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'средняя общеобразовательная школа', 'СОШ')\n",
    "    replaceInRow(df_m, 'Уч_Заведение', 'средняя школа', 'СОШ')\n",
    "    \n",
    "    #replaceInRow(df_m, 'Уч_Заведение', 'Г-А', 'ВУЗГА')\n",
    "    \n",
    "    if False:    \n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайский государственный технический университет', polith_name)\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Средняя общеобразовательная школа', 'СОШ')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Г-А государственный университет', 'Г-А-ГУ')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайский промышленно-экономический колледж', 'Алтайский_промышленно-экономический_колледж')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайская академия экономики и права', 'Алтайская_академия_экономики_и_права')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайский государственный педагогический университет', 'Алтайский_государственный_педагогический_университет')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Барнаульский государственный педагогический университет', 'Алтайский_государственный_педагогический_университет')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Барнаульский государственный педагогический колледж', \n",
    "                     'Барнаульский_государственный_педагогический_колледж')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайский государственный аграрный университет', \n",
    "                     'Алтайский_государственный_аграрный_университет')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайская академия гостеприимства', \n",
    "                     'Алтайская_академия_гостеприимства')\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Российская академия народного хозяйства', \n",
    "                     'Российская_академия_народного хозяйства')    \n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайская государственная педагогическая академия', \n",
    "                     'Алтайская_государственная_педагогическая_академия')   \n",
    "\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Бийский государственный колледж', \n",
    "                     'Бийский_государственный_колледж')   \n",
    "\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Алтайский государственный медицинский университет', \n",
    "                     'а_г_Мед_у')   \n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'крайпотребсоюза', \n",
    "                     'техникум_крайпотребсоюза')   \n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Восточно-Казахстанский государственный университет', \n",
    "                     'Восточно-Казахстанский государственный университет')\n",
    "\n",
    "        replaceInRow(df_m, 'Уч_Заведение', 'Барнаульский торгово-экономический колледж', \n",
    "                     'Барнаульский торгово-экономический колледж')    \n",
    "    \n",
    "\n",
    "    \n",
    "    topoFixCountry(df_m, 'Страна_ПП')\n",
    "    topoFixCountry(df_m, 'Страна_Родители')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    df_m['Город_ПП'].fillna('', inplace=True)\n",
    "    df_m['Регион_ПП'].fillna('', inplace=True)\n",
    "    df_m['Иностранец'].fillna(0.0, inplace=True)\n",
    "    replaceInRowSimple(df_m, 'Регион_ПП', 'область', 'обл')\n",
    "    replaceInRowSimple(df_m, 'Регион_ПП', 'обл.', 'обл')\n",
    "\n",
    "\n",
    "    replaceInRow(df_m, 'Регион_ПП', 'Алтайский ', 'Алтайский край')\n",
    "    replaceInRow(df_m, 'Регион_ПП', 'Алайский край', 'Алтайский край')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #replaceInRow(df_m, 'Регион_ПП', 'Алтай респ', 'Республика Алтай')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    topoFix(df_m, 'Город_ПП')\n",
    "    topoFix(df_m, 'Где_Находится_УЗ')\n",
    "       \n",
    "    \n",
    "    df_m.loc[df['Изучаемый_Язык'] == 'Русский язык', 'Изучаемый_Язык'] = 'Английский язык'\n",
    "    \n",
    "    df_m['Изучаемый_Язык'].fillna('', inplace=True)\n",
    "    \n",
    "    df_m['Изучаемый_Язык'] = df_m.apply(lambda row: row['Изучаемый_Язык'] if str(row['Изучаемый_Язык']).find(\"Англ\") == -1 else  \"Английский язык\", axis=1)\n",
    "    df_m['Изучаемый_Язык'] = df_m.apply(lambda row: row['Изучаемый_Язык'] if str(row['Изучаемый_Язык']).find(\"Нем\") == -1 else  \"Немецкий язык\", axis=1)\n",
    "    \n",
    "    return df_m\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fixValues(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_map = {}\n",
    "#df = pd.read_csv(\"train_dataset_train.csv\")\n",
    "\n",
    "col_name ='Страна_Родители' \n",
    "\n",
    "gl_map[col_name] = df[col_name].unique().tolist()\n",
    "\n",
    "col_name ='Изучаемый_Язык' \n",
    "\n",
    "gl_map[col_name] = df[col_name].unique().tolist()\n",
    "\n",
    "col_name ='Страна_ПП' \n",
    "\n",
    "gl_map[col_name] = df[col_name].unique().tolist()\n",
    "\n",
    "col_name ='Где_Находится_УЗ' \n",
    "\n",
    "gl_map[col_name] = df[col_name].unique().tolist()\n",
    "\n",
    "col_name ='Город_ПП' \n",
    "\n",
    "gl_map[col_name] = df[col_name].unique().tolist()\n",
    "\n",
    "col_name ='Уч_Заведение' \n",
    "\n",
    "gl_map[col_name] = df[col_name].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "col_name ='Регион_ПП' \n",
    "\n",
    "gl_map[col_name] = df[col_name].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "#vus_map.index('муж')\n",
    "\n",
    "def getVusIndex(row, colName):\n",
    "    valueCell = row[colName]\n",
    "    if valueCell not in gl_map[colName]:\n",
    "        return -1\n",
    "    else:\n",
    "        return gl_map[colName].index(valueCell)\n",
    "    \n",
    "def findVO(row):\n",
    "    valRow = str(row['Уч_Заведение'])\n",
    "    \n",
    "    res = valRow.find(\" ВО \") > -1 or valRow.find(\" ВПО \") > -1 or valRow.find(\"нститут\") > -1 \n",
    "    return (res)*1\n",
    "    \n",
    "def findSH(row):\n",
    "    valRow = str(row['Уч_Заведение'])\n",
    "    \n",
    "    res = valRow.find(\"СОШ\") > -1 or valRow.find(\"кола\") > -1 \n",
    "    return (res)*1\n",
    "\n",
    "def findSH_VIP(row):\n",
    "    valRow = str(row['Уч_Заведение'])\n",
    "    \n",
    "    res = valRow.find(\"имназия\") > -1 or valRow.find(\"лицей\") > -1 or valRow.find(\"колледж\") > -1 \n",
    "    return (res)*1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_ageIn(born):\n",
    "    bd = born['Дата_Рождения']\n",
    "    \n",
    "    f = \"%Y-%m-%d 00:00:00.000\"\n",
    "    \n",
    "    inY = born['Год_Поступления']\n",
    "    if inY < 1900:\n",
    "        return 17\n",
    "    today = date.today()\n",
    "    yearsAgoIN = today.year - inY\n",
    "    born = datetime.strptime(bd, f)\n",
    "    \n",
    "    \n",
    "    age = today.year - born.year - ((today.month, 5) < (born.month, born.day))\n",
    "    ageOnIn = age - yearsAgoIN\n",
    "    if ageOnIn < 8:\n",
    "        return 18\n",
    "    return ageOnIn\n",
    "\n",
    "def calculate_InOld(row):\n",
    "    today = date.today()\n",
    "    if row['Год_Окончания_УЗ'] < 10 or  row['Год_Поступления'] < 10:\n",
    "        return 0\n",
    "    return today.year - row['Год_Поступления']\n",
    "\n",
    "def calculate_gap(row):\n",
    "    \n",
    "    if row['Год_Окончания_УЗ'] < 10 or  row['Год_Поступления'] < 10:\n",
    "        return 0\n",
    "    return row['Год_Поступления'] - row['Год_Окончания_УЗ']\n",
    "\n",
    "def form_mark(val):\n",
    "    if val > 100:\n",
    "        val = val /1000\n",
    "    #val = row['СрБаллАттестата']\n",
    "    if val < 5:\n",
    "        return (val/5)*80/100\n",
    "    return val/100\n",
    "\n",
    "def form_mark_2(val):\n",
    "    if val > 1000:\n",
    "        val = val /1000\n",
    "    #val = row['СрБаллАттестата']\n",
    "    if val < 7:\n",
    "        return (val/5)*80/100\n",
    "    return val/100\n",
    "print(form_mark(2))\n",
    "\n",
    "print(form_mark(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9N4JbcWudk2"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"train_dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wom_int'] = df.apply(lambda row: (row['Пол'] == 'Жен')*1.0, axis=1)\n",
    "gp = df.groupby(['Код_группы']).agg({'wom_int': ['mean']}).reset_index()\n",
    "m_map = {}\n",
    "for index, row in gp.iterrows():\n",
    "    m_map[int(row['Код_группы'])] = float(row['wom_int'])\n",
    "\n",
    "\n",
    "#print(m_map)\n",
    "df['ball4'] = df.apply(lambda row: form_mark_2(row['СрБаллАттестата']), axis=1)\n",
    "gp = df.groupby(['КодФакультета']).agg({'ball4': ['mean']}).reset_index()\n",
    "b_map = {}\n",
    "for index, row in gp.iterrows():\n",
    "    b_map[int(row['КодФакультета'])] = float(row['ball4'])\n",
    "    \n",
    "\n",
    "#--------------------------------\n",
    "gp = df.groupby(['КодФакультета']).agg({'wom_int': ['mean']}).reset_index()\n",
    "kaf_pol_map = {}\n",
    "for index, row in gp.iterrows():\n",
    "    kaf_pol_map[int(row['КодФакультета'])] = float(row['wom_int'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgCS5B_PutbW"
   },
   "source": [
    "## Рассмотрим датасет по ближе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "qEvfySMMutBR",
    "outputId": "4dfb8e9e-8953-4111-d155-30994b74e6b2"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"train_dataset_train.csv\")\n",
    "\n",
    "def fillFields(df_i):\n",
    "    #df_i['man_int'] = df_i.apply(lambda row: (row['Пол'] == 'Муж')*1, axis=1)\n",
    "    df_i['wom_int'] = df_i.apply(lambda row: (row['Пол'] == 'Жен')*1, axis=1)\n",
    "    df_i['lang_int'] = df_i.apply(lambda row: getVusIndex(row,'Изучаемый_Язык'), axis=1)\n",
    "    df_i['prCt_int'] = df_i.apply(lambda row: getVusIndex(row,'Страна_Родители'), axis=1)\n",
    "\n",
    "    df_i['ctPP_int'] = df_i.apply(lambda row: getVusIndex(row,'Страна_ПП'), axis=1)\n",
    "    df_i['US_location_in'] = df_i.apply(lambda row: getVusIndex(row,'Где_Находится_УЗ'), axis=1)\n",
    "\n",
    "    df_i['reg_pp_in'] = df_i.apply(lambda row: getVusIndex(row,'Регион_ПП'), axis=1)\n",
    "    df_i['gorod_pp_in'] = df_i.apply(lambda row: getVusIndex(row,'Город_ПП'), axis=1)\n",
    "    df_i['uch_zav_indx'] = df_i.apply(lambda row: getVusIndex(row,'Уч_Заведение'), axis=1)\n",
    "    \n",
    "\n",
    "    df_i['oldIn'] = df_i.apply(lambda row: calculate_InOld(row), axis=1)\n",
    "    df_i['m_pol'] = df_i.apply(lambda row: 0.5 if int(row['Код_группы']) not in m_map else  m_map[int(row['Код_группы'])], axis=1)\n",
    "\n",
    "    #df_i['KG_even'] = df_i.apply(lambda row: row['Код_группы']%2 , axis=1)\n",
    "    #df_i['KG_big'] = df_i.apply(lambda row: (row['Код_группы']<14000)*1 , axis=1)\n",
    "\n",
    "\n",
    "    #df_i['monBr'] = df_i.apply(lambda row: calculate_monBr(row['Дата_Рождения']), axis=1)\n",
    "\n",
    "    #df_i['isUniver'] = df_i.apply(lambda row: (str(row['Уч_Заведение']).find(\"универ\") > -1)*1, axis=1)\n",
    "    #df_i['isVO'] = df_i.apply(lambda row: findVO(row), axis=1)\n",
    "    #df_i['isMBOU'] = df_i.apply(lambda row: (str(row['Уч_Заведение']).find(\"МБОУ\") > -1)*1, axis=1)\n",
    "    #df_i['isSH'] = df_i.apply(lambda row: findSH(row), axis=1)\n",
    "    #df_i['isSH_VIP'] = df_i.apply(lambda row: findSH_VIP(row), axis=1)\n",
    "\n",
    "    #df_i['US_len'] = df_i.apply(lambda row: len(str(row['Уч_Заведение'])), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_i['gap'] = df_i.apply(lambda row: calculate_gap(row), axis=1)\n",
    "\n",
    "    df_i['os_oo'] = df_i.apply(lambda row: (row['Основания'] == 'ОО')*1, axis=1)\n",
    "    df_i['os_cn'] = df_i.apply(lambda row: (row['Основания'] == 'ЦН')*1, axis=1)\n",
    "    df_i['os_dn'] = df_i.apply(lambda row: (row['Основания'] == 'ДН')*1, axis=1)\n",
    "    df_i['os_bn'] = df_i.apply(lambda row: (row['Основания'] == 'БН')*1, axis=1)\n",
    "    df_i['os_sn'] = df_i.apply(lambda row: (row['Основания'] == 'СН')*1, axis=1)\n",
    "    df_i['age'] = df_i.apply(lambda row: calculate_age(row['Дата_Рождения']), axis=1)\n",
    "    df_i['ageIn'] = df_i.apply(lambda row: calculate_ageIn(row), axis=1)\n",
    "    #df_i['seloTo'] = df_i.apply(lambda row: (str(row['Город_ПП']).find('Барнаул') > -1 or row['Село'] >0 )*1, axis=1)\n",
    "    #df_i['isRus'] = df_i.apply(lambda row: (row['Страна_ПП'] == 'Россия')*1, axis=1)\n",
    "    df_i['ball4'] = df_i.apply(lambda row: form_mark_2(row['СрБаллАттестата']), axis=1)\n",
    "    #df_i['ball4_10'] = df_i.apply(lambda row: (row['СрБаллАттестата'] < 5 and row['СрБаллАттестата'] < 11)*1, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    df_i['b_pol'] = df_i.apply(lambda row: b_map[int(row['КодФакультета'])], axis=1)\n",
    "\n",
    "    df_i['kaf_pol_mean'] = df_i.apply(lambda row: kaf_pol_map[int(row['КодФакультета'])], axis=1)\n",
    "    \n",
    "\n",
    "    #print(b_map)\n",
    "\n",
    "    #df_i['os_sn'] = df_i.apply(lambda row: (row['Основания'] == 'СН')*1, axis=1)\n",
    "\n",
    "    df_i = df_i.fillna(0)\n",
    "    return df_i\n",
    "\n",
    "df =fillFields(df)\n",
    "#Tmp =  df[[\"isVO\", 'Уч_Заведение', 'ball4', 'm_pol']]\n",
    "#Tmp.head(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cxnT51gu5fJ"
   },
   "source": [
    "Пострим на распределение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "205eCTRPu3Au",
    "outputId": "190a476b-9204-46e8-835d-419c8c80bceb"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x = \"ball4\" , data  = df).set_title('Распределение предсказываемой величены')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0CkiEzGwusL"
   },
   "source": [
    "Взглянем на несколько величин сразу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr-31zZQxUwx"
   },
   "source": [
    "Обратим внимание на часть столбцов с постоянными значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 883
    },
    "id": "VnDPAAahyOnw",
    "outputId": "13ba8161-1b04-47f2-cf76-52a99ab762b0"
   },
   "outputs": [],
   "source": [
    "\n",
    "fld_list = [ 'Общежитие', \n",
    "            'Наличие_Матери', \n",
    "            'КодФакультета', \n",
    "            #'Год_Поступления',\n",
    "            \"wom_int\",\n",
    "                'ball4', \n",
    "            'uch_zav_indx',\n",
    "            #'isUniver',\n",
    "            #'isVO',\n",
    "            #'isMBOU',\n",
    "            #'isSH_VIP',\n",
    "            #'isSH',\n",
    "            'US_location_in',\n",
    "            'reg_pp_in',\n",
    "            'gorod_pp_in',\n",
    "            'oldIn',\n",
    "           \n",
    "            #'СрБаллАттестата',\n",
    "            #'monBr',\n",
    "            #'KG_even',\n",
    "            #'KG_big',\n",
    "            #'US_len',\n",
    "            'gap',\n",
    "            'age',\n",
    "            'Иностранец', \n",
    "            'os_dn', \n",
    "            'os_bn', \n",
    "            'Село',\n",
    "            'lang_int', \n",
    "            'os_oo',\n",
    "            'os_cn', \n",
    "            'os_sn', \n",
    "             'b_pol',\n",
    "            'prCt_int', \n",
    "            'ctPP_int',\n",
    "            'm_pol',\n",
    "            \n",
    "            'kaf_pol_mean',\n",
    "             'Код_группы',\n",
    "           ]\n",
    "\n",
    "\n",
    "fld_list_1 = [ \n",
    "            'Код_группы',\n",
    "    'Год_Поступления',\n",
    "    'm_pol',\n",
    "    'ball4', \n",
    "                  'Село',       \n",
    "     'Иностранец',\n",
    "    'ageIn',\n",
    "            \"wom_int\",\n",
    "\n",
    "                  'os_dn', \n",
    "            'os_bn',    \n",
    "    'b_pol'\n",
    "           ]\n",
    "\n",
    "fld_list_diag = fld_list.copy()\n",
    "fld_list_diag.append('Статус')\n",
    "plt.rcParams['figure.figsize']=(15,15)\n",
    "\n",
    "\n",
    "#df_corr = list(set(df.columns.values) - set(['Опекунство','Пособие','Наличие_Матери', 'СрБаллАттестата', 'Год_Окончания_УЗ']))\n",
    "g = sns.heatmap(df[fld_list_diag].corr(), square = True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLOa56f5zfUg"
   },
   "source": [
    "## Выделим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5wEuIQ50ibJ",
    "outputId": "a2e6c3fd-f3b5-4beb-c904-3d082119e3be"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "845Wf3zJ1dhc"
   },
   "source": [
    "Поместим все столбцы object в массив, для их дальнейшего удаления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAhVoVTj1l-D"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Resample the minority class. You can change the strategy to 'auto' if you are not sure.\n",
    "sm = SMOTE(sampling_strategy='all', random_state=7) #minority\n",
    "\n",
    "\n",
    "\n",
    "print(fld_list)\n",
    "\n",
    "#mass_object = np.append(mass_object, \"Год_Поступления\")\n",
    "\n",
    "X = df[fld_list]\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "y = df[[\"Статус\"]]\n",
    "\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение модели\n",
    "#{'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 22, 'criterion': 'entropy'}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=10, criterion=\"entropy\",random_state=0, n_estimators=5000, max_depth=21, min_samples_split=2, min_samples_leaf=1 )\n",
    "#clf = RandomForestClassifier(n_jobs=10, criterion=\"entropy\",random_state=0, n_estimators=150, max_depth=20, min_samples_split=19, min_samples_leaf=2 )\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "#from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#bclf = BaggingClassifier(base_estimator=clf,    n_estimators=10, random_state=0)\n",
    "#bclf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "#print(pred.shape)\n",
    "#print(pred)\n",
    "#Оценка точности\n",
    "print(f1_score(y_test, pred, average='macro', zero_division = 0))\n",
    "disp = metrics.plot_confusion_matrix(clf, X_test, y_test , normalize='true')\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjJp2a4dFmNJ"
   },
   "source": [
    "# Cоздание файла с ответом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJXTk60rGZxn"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/test_dataset_test.csv\", index_col=False)\n",
    "df_submission = pd.read_csv(\"data/submission_baseline.csv\", index_col=False)\n",
    "\n",
    "\n",
    "df_test = fixValues(df_test)\n",
    "\n",
    "df_test = fillFields(df_test)\n",
    "\n",
    "\n",
    "\n",
    "df_test = df_test[fld_list]\n",
    "\n",
    "\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#df_test = scaler.fit_transform(df_test)\n",
    "#df_test\n",
    "#df_test.head(3)\n",
    "df_test_pred = clf.predict(df_test)\n",
    "df_submission[\"Статус\"] = df_test_pred\n",
    "df_submission.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lYg_cpvBbcg"
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(\"sub/submission_8_50_5000_def_re.csv\", index=False)#13 для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "students_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
